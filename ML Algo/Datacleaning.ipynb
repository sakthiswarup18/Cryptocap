{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id symbol      name  current_price    market_cap  market_cap_rank  \\\n",
      "0   bitcoin    btc   Bitcoin     101205.000  2.000380e+12                1   \n",
      "1  ethereum    eth  Ethereum       3908.910  4.699840e+11                2   \n",
      "2    ripple    xrp       XRP          2.410  1.373320e+11                3   \n",
      "3    tether   usdt    Tether          1.001  1.358230e+11                4   \n",
      "4    solana    sol    Solana        239.890  1.138580e+11                5   \n",
      "\n",
      "   fully_diluted_valuation  total_volume    high_24h       low_24h  ...  \\\n",
      "0             2.122630e+12  1.434480e+11  103679.000  94870.000000  ...   \n",
      "1             4.699840e+11  6.255699e+10    3946.580   3774.780000  ...   \n",
      "2             2.406840e+11  2.759453e+10       2.470      2.210000  ...   \n",
      "3             1.358230e+11  1.809590e+11       1.012      0.994958  ...   \n",
      "4             1.412160e+11  1.160859e+10     244.110    224.400000  ...   \n",
      "\n",
      "   total_supply    max_supply  All_Time_High  ATH_Change_Percentage  \\\n",
      "0  2.100000e+07  2.100000e+07      103679.00               -2.38510   \n",
      "1  1.204419e+08  0.000000e+00        4878.26              -19.91576   \n",
      "2  9.998695e+10  1.000000e+11           3.40              -29.01621   \n",
      "3  1.356910e+11  0.000000e+00           1.32              -24.41732   \n",
      "4  5.895604e+08  0.000000e+00         263.21               -8.95689   \n",
      "\n",
      "                          ATH_Date  All_Time_Low  ATL_Change_Percentage  \\\n",
      "0 2024-12-05 03:10:51.885000+00:00     67.810000          -2.894026e+07   \n",
      "1 2021-11-10 14:24:19.604000+00:00      0.432979          -2.894026e+07   \n",
      "2        2018-01-07 00:00:00+00:00      0.002686          -2.894026e+07   \n",
      "3        2018-07-24 00:00:00+00:00      0.572521          -2.894026e+07   \n",
      "4 2024-11-23 15:05:59.896000+00:00      0.500801          -2.894026e+07   \n",
      "\n",
      "                          ATL_Date  roi                     Last_Updated  \n",
      "0        2013-07-06 00:00:00+00:00  0.0 2024-12-05 17:07:54.462000+00:00  \n",
      "1        2015-10-20 00:00:00+00:00  0.0 2024-12-05 17:07:56.189000+00:00  \n",
      "2        2014-05-22 00:00:00+00:00  0.0 2024-12-05 17:07:54.059000+00:00  \n",
      "3        2015-03-02 00:00:00+00:00  0.0 2024-12-05 17:07:56.088000+00:00  \n",
      "4 2020-05-11 19:35:23.449000+00:00  0.0 2024-12-05 17:07:53.264000+00:00  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the provided CSV file\n",
    "file_path = 'all_coins_data.csv'\n",
    "all_coins_data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Handle Missing Values\n",
    "# Fill NaN values for 'fully_diluted_valuation', 'max_supply', and 'roi' with 0, since they represent missing data\n",
    "all_coins_data['fully_diluted_valuation'].fillna(0, inplace=True)\n",
    "all_coins_data['max_supply'].fillna(0, inplace=True)\n",
    "all_coins_data['roi'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 2: Convert Date Columns to Datetime\n",
    "all_coins_data['ath_date'] = pd.to_datetime(all_coins_data['ath_date'], errors='coerce')\n",
    "all_coins_data['atl_date'] = pd.to_datetime(all_coins_data['atl_date'], errors='coerce')\n",
    "all_coins_data['last_updated'] = pd.to_datetime(all_coins_data['last_updated'], errors='coerce')\n",
    "\n",
    "# Step 3: Drop Unnecessary Columns\n",
    "# Drop 'image' column as it is not useful for analysis\n",
    "all_coins_data.drop(columns=['image'], inplace=True)\n",
    "\n",
    "# Step 4: Rename Columns for Readability\n",
    "all_coins_data.rename(columns={\n",
    "    'ath': 'All_Time_High',\n",
    "    'atl': 'All_Time_Low',\n",
    "    'ath_change_percentage': 'ATH_Change_Percentage',\n",
    "    'atl_change_percentage': 'ATL_Change_Percentage',\n",
    "    'ath_date': 'ATH_Date',\n",
    "    'atl_date': 'ATL_Date',\n",
    "    'last_updated': 'Last_Updated',\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 5: Fix Data Types if necessary\n",
    "# Ensure numeric columns are in float format\n",
    "numeric_columns = [\n",
    "    'current_price', 'market_cap', 'fully_diluted_valuation', 'total_volume',\n",
    "    'high_24h', 'low_24h', 'All_Time_High', 'All_Time_Low',\n",
    "    'ATH_Change_Percentage', 'ATL_Change_Percentage'\n",
    "]\n",
    "all_coins_data[numeric_columns] = all_coins_data[numeric_columns].astype(float)\n",
    "\n",
    "# Step 6: Handle Outliers\n",
    "# Identify and cap extreme outliers for ATH and ATL change percentages\n",
    "# Capping to a reasonable percentile (e.g., 99.5%) to reduce skew due to extreme outliers\n",
    "for col in ['ATH_Change_Percentage', 'ATL_Change_Percentage']:\n",
    "    upper_limit = all_coins_data[col].quantile(0.995)\n",
    "    all_coins_data[col] = all_coins_data[col].clip(upper=-upper_limit)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(all_coins_data.head())\n",
    "\n",
    "# Optionally, save the cleaned dataframe to a new CSV file\n",
    "# all_coins_data.to_csv('cleaned_all_coins_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp  Asset_ID  Count           Open        High           Low  \\\n",
      "0  1733418474       1.0   1474  100547.977924  103679.000  94870.000000   \n",
      "1  1733418476       2.0    727    3844.632256    3946.580   3774.780000   \n",
      "2  1733418474       3.0   1088       2.391609       2.470      2.210000   \n",
      "3  1733418476       4.0   1695       0.989428       1.012      0.994958   \n",
      "4  1733418473       5.0    956     237.955155     244.110    224.400000   \n",
      "\n",
      "        Close        Volume          VWAP  group_num  row_id  \n",
      "0  101205.000  1.434480e+11  99918.000000          0       0  \n",
      "1    3908.910  6.255699e+10   3876.756667          0       1  \n",
      "2       2.410  2.759453e+10      2.363333          0       2  \n",
      "3       1.001  1.809590e+11      1.002653          0       3  \n",
      "4     239.890  1.160859e+10    236.133333          0       4  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the provided CSV file\n",
    "all_coins_data = pd.read_csv('all_coins_data.csv')\n",
    "\n",
    "# Extract relevant columns from all_coins_data\n",
    "all_coins_data_subset = all_coins_data[['id', 'symbol', 'current_price', 'total_volume', 'high_24h', 'low_24h', 'last_updated']]\n",
    "\n",
    "# Convert 'last_updated' to timestamp and add it to the new dataframe\n",
    "all_coins_data_subset = all_coins_data_subset.copy()  # Create a copy to avoid potential pitfalls\n",
    "all_coins_data_subset['timestamp'] = pd.to_datetime(all_coins_data_subset['last_updated'], errors='coerce').astype(np.int64) // 10**9\n",
    "\n",
    "all_coins_transformed = all_coins_data_subset.rename(columns={\n",
    "    'id': 'Asset_ID',\n",
    "    'current_price': 'Close',\n",
    "    'high_24h': 'High',\n",
    "    'low_24h': 'Low',\n",
    "    'total_volume': 'Volume'\n",
    "})\n",
    "\n",
    "# Create a numerical Asset_ID for the new data\n",
    "# Assign new numerical IDs to the Asset_ID field, starting from 1\n",
    "asset_id_mapping = {name: idx for idx, name in enumerate(all_coins_transformed['Asset_ID'].unique(), start=1)}\n",
    "all_coins_transformed['Asset_ID'] = all_coins_transformed['Asset_ID'].map(asset_id_mapping)\n",
    "\n",
    "all_coins_transformed['Asset_ID'] = all_coins_transformed['Asset_ID'].astype(float)\n",
    "\n",
    "all_coins_transformed['Count'] = np.random.randint(500, 2000, size=len(all_coins_transformed))\n",
    "all_coins_transformed['Open'] = all_coins_transformed['Close'] * np.random.uniform(0.98, 1.02, size=len(all_coins_transformed))\n",
    "\n",
    "all_coins_transformed['Open'] = all_coins_transformed['Open'].fillna(0)  # Or any placeholder value\n",
    "\n",
    "all_coins_transformed['VWAP'] = (all_coins_transformed['High'] + all_coins_transformed['Low'] + all_coins_transformed['Close']) / 3\n",
    "all_coins_transformed['VWAP'] = all_coins_transformed['VWAP'].fillna(0)  # Handle NaN in VWAP\n",
    "\n",
    "all_coins_transformed['group_num'] = 0  \n",
    "all_coins_transformed['row_id'] = all_coins_transformed.index  # Row index as ID\n",
    "\n",
    "# Reorder columns to match the desired structure\n",
    "all_coins_transformed = all_coins_transformed[['timestamp', 'Asset_ID', 'Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP', 'group_num', 'row_id']]\n",
    "\n",
    "# Save the transformed data to a new CSV file\n",
    "all_coins_transformed.to_csv('transformed_all_coins_data.csv', index=False)\n",
    "\n",
    "# Optionally, print the first few rows to verify\n",
    "print(all_coins_transformed.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
