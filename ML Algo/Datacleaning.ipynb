{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id symbol      name  current_price    market_cap  market_cap_rank  \\\n",
      "0   bitcoin    btc   Bitcoin     101205.000  2.000380e+12                1   \n",
      "1  ethereum    eth  Ethereum       3908.910  4.699840e+11                2   \n",
      "2    ripple    xrp       XRP          2.410  1.373320e+11                3   \n",
      "3    tether   usdt    Tether          1.001  1.358230e+11                4   \n",
      "4    solana    sol    Solana        239.890  1.138580e+11                5   \n",
      "\n",
      "   fully_diluted_valuation  total_volume    high_24h       low_24h  ...  \\\n",
      "0             2.122630e+12  1.434480e+11  103679.000  94870.000000  ...   \n",
      "1             4.699840e+11  6.255699e+10    3946.580   3774.780000  ...   \n",
      "2             2.406840e+11  2.759453e+10       2.470      2.210000  ...   \n",
      "3             1.358230e+11  1.809590e+11       1.012      0.994958  ...   \n",
      "4             1.412160e+11  1.160859e+10     244.110    224.400000  ...   \n",
      "\n",
      "   total_supply    max_supply  All_Time_High  ATH_Change_Percentage  \\\n",
      "0  2.100000e+07  2.100000e+07      103679.00               -2.38510   \n",
      "1  1.204419e+08  0.000000e+00        4878.26              -19.91576   \n",
      "2  9.998695e+10  1.000000e+11           3.40              -29.01621   \n",
      "3  1.356910e+11  0.000000e+00           1.32              -24.41732   \n",
      "4  5.895604e+08  0.000000e+00         263.21               -8.95689   \n",
      "\n",
      "                          ATH_Date  All_Time_Low  ATL_Change_Percentage  \\\n",
      "0 2024-12-05 03:10:51.885000+00:00     67.810000          -2.894026e+07   \n",
      "1 2021-11-10 14:24:19.604000+00:00      0.432979          -2.894026e+07   \n",
      "2        2018-01-07 00:00:00+00:00      0.002686          -2.894026e+07   \n",
      "3        2018-07-24 00:00:00+00:00      0.572521          -2.894026e+07   \n",
      "4 2024-11-23 15:05:59.896000+00:00      0.500801          -2.894026e+07   \n",
      "\n",
      "                          ATL_Date  roi                     Last_Updated  \n",
      "0        2013-07-06 00:00:00+00:00  0.0 2024-12-05 17:07:54.462000+00:00  \n",
      "1        2015-10-20 00:00:00+00:00  0.0 2024-12-05 17:07:56.189000+00:00  \n",
      "2        2014-05-22 00:00:00+00:00  0.0 2024-12-05 17:07:54.059000+00:00  \n",
      "3        2015-03-02 00:00:00+00:00  0.0 2024-12-05 17:07:56.088000+00:00  \n",
      "4 2020-05-11 19:35:23.449000+00:00  0.0 2024-12-05 17:07:53.264000+00:00  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the provided CSV file\n",
    "file_path = 'all_coins_data.csv'\n",
    "all_coins_data = pd.read_csv(file_path)\n",
    "\n",
    "# Step 1: Handle Missing Values\n",
    "# Fill NaN values for 'fully_diluted_valuation', 'max_supply', and 'roi' with 0, since they represent missing data\n",
    "all_coins_data['fully_diluted_valuation'].fillna(0, inplace=True)\n",
    "all_coins_data['max_supply'].fillna(0, inplace=True)\n",
    "all_coins_data['roi'].fillna(0, inplace=True)\n",
    "\n",
    "# Step 2: Convert Date Columns to Datetime\n",
    "all_coins_data['ath_date'] = pd.to_datetime(all_coins_data['ath_date'], errors='coerce')\n",
    "all_coins_data['atl_date'] = pd.to_datetime(all_coins_data['atl_date'], errors='coerce')\n",
    "all_coins_data['last_updated'] = pd.to_datetime(all_coins_data['last_updated'], errors='coerce')\n",
    "\n",
    "# Step 3: Drop Unnecessary Columns\n",
    "# Drop 'image' column as it is not useful for analysis\n",
    "all_coins_data.drop(columns=['image'], inplace=True)\n",
    "\n",
    "# Step 4: Rename Columns for Readability\n",
    "all_coins_data.rename(columns={\n",
    "    'ath': 'All_Time_High',\n",
    "    'atl': 'All_Time_Low',\n",
    "    'ath_change_percentage': 'ATH_Change_Percentage',\n",
    "    'atl_change_percentage': 'ATL_Change_Percentage',\n",
    "    'ath_date': 'ATH_Date',\n",
    "    'atl_date': 'ATL_Date',\n",
    "    'last_updated': 'Last_Updated',\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 5: Fix Data Types if necessary\n",
    "# Ensure numeric columns are in float format\n",
    "numeric_columns = [\n",
    "    'current_price', 'market_cap', 'fully_diluted_valuation', 'total_volume',\n",
    "    'high_24h', 'low_24h', 'All_Time_High', 'All_Time_Low',\n",
    "    'ATH_Change_Percentage', 'ATL_Change_Percentage'\n",
    "]\n",
    "all_coins_data[numeric_columns] = all_coins_data[numeric_columns].astype(float)\n",
    "\n",
    "# Step 6: Handle Outliers\n",
    "# Identify and cap extreme outliers for ATH and ATL change percentages\n",
    "# Capping to a reasonable percentile (e.g., 99.5%) to reduce skew due to extreme outliers\n",
    "for col in ['ATH_Change_Percentage', 'ATL_Change_Percentage']:\n",
    "    upper_limit = all_coins_data[col].quantile(0.995)\n",
    "    all_coins_data[col] = all_coins_data[col].clip(upper=-upper_limit)\n",
    "\n",
    "# Display the cleaned data\n",
    "print(all_coins_data.head())\n",
    "\n",
    "# Optionally, save the cleaned dataframe to a new CSV file\n",
    "# all_coins_data.to_csv('cleaned_all_coins_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp  Asset_ID  Count          Open        High           Low  \\\n",
      "0  1733418474       1.0   1069  99586.645811  103679.000  94870.000000   \n",
      "1  1733418476       2.0   1073   3966.850385    3946.580   3774.780000   \n",
      "2  1733418474       3.0   1906      2.427242       2.470      2.210000   \n",
      "3  1733418476       4.0   1699      0.983331       1.012      0.994958   \n",
      "4  1733418473       5.0   1103    240.095146     244.110    224.400000   \n",
      "\n",
      "        Close        Volume          VWAP  group_num  row_id  \n",
      "0  101205.000  1.434480e+11  99918.000000          0       0  \n",
      "1    3908.910  6.255699e+10   3876.756667          0       1  \n",
      "2       2.410  2.759453e+10      2.363333          0       2  \n",
      "3       1.001  1.809590e+11      1.002653          0       3  \n",
      "4     239.890  1.160859e+10    236.133333          0       4  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the provided CSV file\n",
    "all_coins_data = pd.read_csv('all_coins_data.csv')\n",
    "\n",
    "# Extract relevant columns from all_coins_data\n",
    "all_coins_data_subset = all_coins_data[['id', 'symbol', 'current_price', 'total_volume', 'high_24h', 'low_24h', 'last_updated']]\n",
    "\n",
    "# Convert 'last_updated' to timestamp and add it to the new dataframe\n",
    "all_coins_data_subset = all_coins_data_subset.copy()  # Create a copy to avoid potential pitfalls\n",
    "all_coins_data_subset['timestamp'] = pd.to_datetime(all_coins_data_subset['last_updated'], errors='coerce').astype(np.int64) // 10**9\n",
    "\n",
    "all_coins_transformed = all_coins_data_subset.rename(columns={\n",
    "    'id': 'Asset_ID',\n",
    "    'current_price': 'Close',\n",
    "    'high_24h': 'High',\n",
    "    'low_24h': 'Low',\n",
    "    'total_volume': 'Volume'\n",
    "})\n",
    "\n",
    "# Create a numerical Asset_ID for the new data\n",
    "# Assign new numerical IDs to the Asset_ID field, starting from 1\n",
    "asset_id_mapping = {name: idx for idx, name in enumerate(all_coins_transformed['Asset_ID'].unique(), start=1)}\n",
    "all_coins_transformed['Asset_ID'] = all_coins_transformed['Asset_ID'].map(asset_id_mapping)\n",
    "\n",
    "all_coins_transformed['Asset_ID'] = all_coins_transformed['Asset_ID'].astype(float)\n",
    "\n",
    "all_coins_transformed['Count'] = np.random.randint(500, 2000, size=len(all_coins_transformed))\n",
    "all_coins_transformed['Open'] = all_coins_transformed['Close'] * np.random.uniform(0.98, 1.02, size=len(all_coins_transformed))\n",
    "\n",
    "all_coins_transformed['Open'] = all_coins_transformed['Open'].fillna(0)  # Or any placeholder value\n",
    "\n",
    "all_coins_transformed['VWAP'] = (all_coins_transformed['High'] + all_coins_transformed['Low'] + all_coins_transformed['Close']) / 3\n",
    "all_coins_transformed['VWAP'] = all_coins_transformed['VWAP'].fillna(0)  # Handle NaN in VWAP\n",
    "\n",
    "all_coins_transformed['group_num'] = 0  \n",
    "all_coins_transformed['row_id'] = all_coins_transformed.index  # Row index as ID\n",
    "\n",
    "# Reorder columns to match the desired structure\n",
    "all_coins_transformed = all_coins_transformed[['timestamp', 'Asset_ID', 'Count', 'Open', 'High', 'Low', 'Close', 'Volume', 'VWAP', 'group_num', 'row_id']]\n",
    "\n",
    "# Save the transformed data to a new CSV file\n",
    "all_coins_transformed.to_csv('transformed_all_coins_data.csv', index=False)\n",
    "\n",
    "# Optionally, print the first few rows to verify\n",
    "print(all_coins_transformed.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      timestamp  Asset_ID  Count_x        Open_x       High_x        Low_x  \\\n",
      "0  1.623542e+09       3.0   1201.0      1.478556      1.48603      1.47800   \n",
      "1  1.623542e+09       2.0   1020.0    580.306667    583.89000    579.91000   \n",
      "2  1.623542e+09       0.0    626.0    343.789500    345.10800    343.64000   \n",
      "3  1.623542e+09       1.0   2888.0  35554.289630  35652.46465  35502.67000   \n",
      "4  1.623542e+09       4.0    433.0      0.312167      0.31260      0.31192   \n",
      "\n",
      "        Close_x       Volume_x        VWAP_x  group_num_x  ...  row_id_y  \\\n",
      "0      1.483681  654799.561100      1.481439          0.0  ...       NaN   \n",
      "1    582.276667    1227.988328    581.697038          0.0  ...       NaN   \n",
      "2    344.598000    1718.832569    344.441729          0.0  ...       NaN   \n",
      "3  35602.004290     163.811537  35583.469300          0.0  ...       NaN   \n",
      "4      0.312208  585577.410400      0.312154          0.0  ...       NaN   \n",
      "\n",
      "   Count  Open  High  Low  Close  Volume  VWAP  group_num  row_id  \n",
      "0    NaN   NaN   NaN  NaN    NaN     NaN   NaN        NaN     NaN  \n",
      "1    NaN   NaN   NaN  NaN    NaN     NaN   NaN        NaN     NaN  \n",
      "2    NaN   NaN   NaN  NaN    NaN     NaN   NaN        NaN     NaN  \n",
      "3    NaN   NaN   NaN  NaN    NaN     NaN   NaN        NaN     NaN  \n",
      "4    NaN   NaN   NaN  NaN    NaN     NaN   NaN        NaN     NaN  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the transformed_all_coins_data CSV\n",
    "transformed_data = pd.read_csv('transformed_all_coins_data.csv')\n",
    "\n",
    "# Load the example_test CSV\n",
    "example_test = pd.read_csv('train.csv')\n",
    "\n",
    "# Merge transformed_all_coins_data with example_test\n",
    "# Assume we want to merge based on the common columns 'timestamp' and 'Asset_ID'\n",
    "example_test_updated = pd.merge(example_test, transformed_data, on=['timestamp', 'Asset_ID'], how='left')\n",
    "\n",
    "# Save the updated example_test dataframe to the same CSV file\n",
    "example_test_updated.to_csv('train.csv', index=False)\n",
    "\n",
    "# Optionally, print the first few rows of the merged data to verify\n",
    "print(example_test_updated.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
